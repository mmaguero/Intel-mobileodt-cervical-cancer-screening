# TODO list
- [x] Implementar función de evaluación logloss según se describe [aquí](https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening#evaluation), **@AythaE**: según he estado buscando esta funcion es conocida como _categorical_crossentropy_, cuya implementación está disponble en keras, pero requiere strings, por eso se define la _sparse_categorical_crossentropy_, que es la función utilizada.
- [x] Lanzar modelo de learning from scratch un numero elevado de epocas para obtener el mejor resultado posible
- [x] Empezar fine-tuning con los modelos de keras
- [ ] Realizar [EDA](https://www.kaggle.com/philschmidt/cervix-eda-model-selection)
- [x] Probar eliminando imagenes incorrectas según se comenta en este [kernel](https://www.kaggle.com/deveaup/checking-bounding-boxes-and-additional-dataset/notebook/notebook) y en [este](https://www.kaggle.com/chiszpanski/non-cervix-images) **@Aythae**: ya están eliminados en los nuevos conjuntos extra
- [x] Probar más data augmentatión en Keras usando [ImagePreprocessing](https://keras.io/preprocessing/image/#imagedatagenerator) **@AythaE**
- [ ] Comparar arquitectura red buena preentrenada con inicialización aleatoria
- [ ] Probar learning from scratch con mas data augmentation e imagenes mejor redimensionadas
- [ ] Lanzar modelo con una red pre-entrenada (inception v3)
- [x] Lanzar modelo con fine-tuning
- [x] Compara fine-tunning vgg e inception. Demasiado computo
- [ ] Extraer caracteristicas con red preentrenada
- [ ] Extraer características con fine-tunning
- [ ] Mirar OVO
- [x] Aplicar OVA
- [ ] Mirar cross validation
- [ ] Mirar como crear ensemble de modelos
